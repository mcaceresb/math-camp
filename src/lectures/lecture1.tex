%! TEX program = pdflatex
%% Mauricio Caceres Bravo <mauricio.caceres.bravo@gmail.com>

%----------------------------------------------------------------------
\documentclass{article}

\usepackage[summary]{brownpreamble}
\usepackage{etoc}
\setcounter{tocdepth}{2}

\renewcommand{\subsectionmark}[1]{\markboth{#1}{}}
\renewcommand\sectiontype{Lecture \thesection:\ }
\lhead{\color{light-gray} \itshape Math Camp Aug 16, 2021 -- Lecture \thesection}
\rhead{\color{light-gray} \itshape \thesubsection. \leftmark}
% \setcounter{section}{0}
% \renewcommand\SetHideLevel{1pt}

%----------------------------------------------------------------------
\begin{document}
\displayoptions

% ---------------------------------------------------------------------
\section{Proofs, Metric Spaces, Topology}
\label{sec:proofs_metric_spaces_topology}

\localtableofcontents

% ---------------------------------------------------------------------
\subsection{Proofs and Logic}
\label{sub:proofs_and_logic}

Math is a language: It should be possible to express anything you want in math, as you would in English or any another language. However, there are many things that are easier to express in math (just like many things are easier to express in English).  One thing that is easier to do in math are proofs.

\subsubsection{If $P$ then $Q$}
\label{ssub:if_p_then_q_}

What does it mean?
\begin{itemize}[label=$\bullet$]
  \item Logically, we say $P \implies Q$, that is, ``$P$ implies $Q$'' or ``$P$ therefore $Q$.''
    \begin{figure}[H]
      \centering
      \begin{tikzpicture}[scale=1]
        \draw [->, >=latex]
          (-2, 0.75) to[bend right=15] (-0.75, 0.25)
          node[above] at (-2, 0.75) {$P$ is sufficient for $Q$};
        \draw [->, >=latex]
          (2, -0.75) to[bend right=15] (0.75, 0.25)
          node[below] at (2, -0.75) {$Q$ is necessary for $P$};
        \node[above] at (0, 0) {$P \implies Q$};
      \end{tikzpicture}
    \end{figure}

  \item Graphically we say $P \subseteq Q$
    \begin{figure}[H]
      \centering
      \begin{tikzpicture}[scale=1]
        \draw (0, 0) circle [radius=1.5];
        \draw (-0.5, -0.5) circle [radius=0.5];
        \node[above] at (-0.5, -0.5) {$P$};
        \node[above] at (0.5, 0.5) {$Q$};
      \end{tikzpicture}
    \end{figure}
\end{itemize}

Naturally, $P \implies Q \ne Q \implies P$; however we have that the \keyword{contrapositive} is equivalent, that is,
\begin{align*}
  P \implies Q \equiv \neg Q \implies \neg P
\end{align*}

This is to say, if not $Q$, then not $P$. Logically, if $P \implies Q$ and we do not have $Q$, then we cannot have $P$ (otherwise we'd have $Q$). Graphically, if we are not in $Q$ and $P \subseteq Q$, then we cannot be in $P$.

\subsubsection{Proof Strategies}
\label{ssub:proof_strategies}

\begin{enumerate}
  \item \keyword{Direct}: Show $P \implies Q$. That is, find some path of logical statements that leads from $P$ to $Q$.
    \begin{example}
      Show $m \in \mathbb{Z}$ even $\implies p \cdot m$ even $\forall p \in \mathbb{Z}$. If $m$ is even, $\exists q \in \mathbb{Z}$ s.t. $m = 2q$, so $pm = 2pq$. Since $pq \in \mathbb{Z}$ we find $pm$ is 2 times an integer, so it is even.
    \end{example}

  \item \keyword{Contrapositive}: If $\neg Q \implies \neg P$. This is very similar to a direct proof, but often it is useful to rephrase a statement we want to prove in its contrapositive form. Further, texts will at times proceed by contrapositive without making explicit mention that is what they are doing.

  \item \keyword{Contradiction}: If $\neg P$ leads to $Q$ and $Q$ is false, then $P$ must be true.
    \begin{example}
      One of the most famous proofs by contradiction is that $\sqrt{2} \notin \mathbb{Q}$. Suppose the negation of that statement, that is, $\sqrt{2} \in \mathbb{Q}$. Recall
      \begin{align*}
        \mathbb{Q} = \Fset{p / q: p, q \in \mathbb{Z} \times \mathbb{Z}\setminus\set{0}}
      \end{align*}

      That means that for some $p, q \in \mathbb{Z} \times \mathbb{Z}\setminus\set{0}$ that are co-primes we have that
      \begin{align*}
        \sqrt{2} = \dfrac{p}{q}
        \iff
        -2 = \dfrac{p^2}{q^2}
        \quad
        \text{or}
        \quad
        2 = \dfrac{p^2}{q^2}
      \end{align*}

      Note that if $\sqrt{2} = \widetilde{p} / \widetilde{q}$ where $\widetilde{p}, \widetilde{q}$ are not co-primes, let $m$ be the product of all the co-factors between them. Now define $p \equiv \widetilde{p} / m$ and $q \equiv \widetilde{q} / m$ to see that $\sqrt{2} = p / q$ for $p, q$ co-primes.  WLOG\footnote{WLOG means ``Without Loss of Generality.'' This is occasionally used in proofs in order to shorten them: This means that even through there is more than one case to consider, proving any of them would follow identical steps to the one you are about to show; hence despite focusing on a specific case, the proof has not lost its general applicability (its generality).} let $2 q^2 = p^2$:
      \begin{align*}
        2q^2 = p^2
        \implies
        p^2 \text{ is even }
        \implies
        p \text{ is even }
        \implies
        \exists m \in \mathbb{Z}: p = 2m
      \end{align*}

      Thus
      \begin{align*}
        2q^2 = (2m)^2
        \iff
        q^2 = 2m^2
        \implies
        q^2 \text{ is even }
        \implies
        q \text{ is even }
        \implies
        \exists n \in \mathbb{Z}: q = 2n
      \end{align*}

      But that means that $p, q$ are not co-primes (they have $2$ as a common factor), a contradiction.
    \end{example}

    There is a very slight nuance with the proof above involving special cases. Can you spot it?\footnote{I believe the common definition of co-prime integers does not preclude both integers from being equal to $1$, in which case my subsequent claims about $p, q$ being even do not hold. If we wanted to be super careful we should say $p, q \ne 1$, but at the same time we can readily see that $1/1 \ne \sqrt{2}$.}

  \item \keyword{Induction}: We want to say something about statements that can be indexed by the natural numbers. Using induction we do that in two steps:
    \begin{enumerate}[a)]
      \item Prove the \keyword{base step}, $P(1)$, is true.

      \item Prove the \keyword{inductive step}, $P(k) \implies P(k + 1)$, is true (i.e. assume $P(k)$ is true and show $P(k + 1)$).
    \end{enumerate}

    \begin{example}
      We want to show that the sum of the first $k$ odd numbers is $k^2$, that is:
      \begin{align*}
        \sum^{k}_{i = 1} 2i - 1 = k^2
      \end{align*}

      For the base case we can see $1 = 1^2$. For the inductive step, assume that $P(k)$ is true show $P(k + 1)$:
      \begin{align*}
        \sum^{k + 1}_{i = 1} 2i - 1
        = \sum^{k}_{i = 1} 2i - 1 + (2k + 1)
        \stackrel{!}{=} k^2 + (2k + 1)
        = (k + 1)^2
      \end{align*}

      where $\stackrel{!}{=}$ is true by the inductive step assumption (if $P(k)$ is true then $\sum^{k}_{i = 1} 2i - 1 = k^2$).
    \end{example}
\end{enumerate}

% ---------------------------------------------------------------------
\subsection{Functions}
\label{sub:functions}

We will not delve too much into set theory. Intuitively, however, we can think of a set as a collection of objects, and we can think of functions as rules that associate every element in one set with an element in another set.\footnote{Formally, we can define a function $f$ from $X$ to $Y$ as a binary relation s.t. $f \subseteq (X \times Y)$ and for each element $x \in X$ there is one (and only one) element $y \in Y$ s.t. $(x, y) \in f$ (though for each element in $y$ there may be some $z \ne x$ s.t. $(z, y) \in f$). Chapter 1 of Ok has a rigorous treatment of functions following an introduction to set theory.}
\begin{definition}[function]\label{def:lecture1_functions}
  $f$ is a \keyword{function} with \keyword{domain} $X$ mapping to a \keyword{co-domain} $Y$ if for every element $x \in X$ there exists a $y \in Y$ s.t. $f(x) = y$. We write $f: X \to Y$, and for any $S \subseteq X$
  \[
    f(S)
    =
    \Fset{
      y \in Y: \exists x \in S ~~ \text{s.t.} ~~ f(x) = y
    }
  \]

  is the \keyword{image} of $S$ under $f$. $f(X)$, the image of the domain, is called the \keyword{range}: The set of points in $Y$ at least some element of $X$ is mapped into.
\end{definition}

\begin{definition}[inverse image]\label{def:lecture1_inverse_image}
  If $f: X \to Y$ then for any $S \subseteq Y$ the \keyword{inverse image} of $S$ is
  \[
    f^{-1}(S)
    =
    \Fset{
      x \in X: \exists y \in S ~~ \text{s.t.} ~~ f(x) = y
    }
  \]
\end{definition}

\begin{remark}
  The inverse image is distinct from the concept of an inverse. A function is invertible if $\exists g$ s.t. $f(x) = y \iff g(y) = x$; this is also denoted $g = f^{-1}$ because the image of the inverse is the inverse image. However, functions needn't be invertible, while the inverse image is always defined.
\end{remark}
In general it need not be the case that $f(X) = Y$, since some points of $Y$ might not be mapped into. Further, a single point in $Y$ might be the mapping of several points in $X$. We have some special interest in functions for which that is not the case.
\begin{definition}[injective]\label{def:lecture1_injective}
  A function $f: X \to Y$ is \keyword{injective} (or onto) if $f(x) = f(y) \implies x = y$.
\end{definition}

\begin{definition}[surjective]\label{def:lecture1_surjective}
  $f$ is \keyword{surjective} (or one-to-one) if $f(X) = Y$.
\end{definition}

\begin{definition}[bijective]\label{def:lecture1_bijective}
  $f$ is \keyword{bijective} or a bijection if it is injective and surjective.
\end{definition}

% ---------------------------------------------------------------------
\subsection{Countability}
\label{sub:countability}

\begin{definition}[countability]\label{def:lecture1_countable}
  A set $X$ is \keyword{countably infinite} or \keyword{countable} if $\exists$ a bijection from $X$ to the natural numbers, $\mathbb{N}$.
\end{definition}

We make a distinction between finite and countable. Some examples of countably infinite sets:
\begin{enumerate}
  \item $\mathbb{N}$ is countable since a bijection from $\mathbb{N} \to \mathbb{N}$ is given by the identity $f(x) = x$.

  \item $\mathbb{Z}$ is countable. This is slightly more complicated, but we can enumerate all the integers:
    \[
      \set{0, -1, 1, -2, 2, \ldots}
    \]

    This is the enumeration given by the bijection $f(x) = 2|x| - 1(x < 0)$
\end{enumerate}

Is $\mathbb{Q}$ countable? Is $\mathbb{R}$? The answers are yes and no, respectively, but the arguments are more nuanced.
\begin{claim}
  $\mathbb{Q}$ is countable.
\end{claim}

\begin{proof}
  Consider the function $g(p, q) = p / q$ defined over $\mathbb{Z} \times \mathbb{Z}\setminus\set{0}$. We can see that $\mathbb{Q} = g(\mathbb{Z} \times \mathbb{Z}\setminus\set{0})$. Hence $\mathbb{Q} \subset \mathbb{Z} \times \mathbb{Z}$, that is, the rational numbers are a subset of the Cartesian product of two countable sets. Since any sub-set of a countable set is countable, if $\mathbb{Z} \times \mathbb{Z}$ is countable the countability of $\mathbb{Q}$ follows immediately. (The intuition is that when we construct the bijection, we can simply ``skip over'' the elements that are not in $\mathbb{Q}$, which in this case would be every alternative representation of a fraction.)

  Take any $P$ and $Q$ countable; then we can enumerate their elements as
  \begin{align*}
    P = \set{p_1, p_2, \ldots}
    \quad
    \text{and}
    \quad
    Q = \set{q_1, q_2, \ldots}
  \end{align*}

  And we can enumerate their Cartesian product as
  \begin{align*}
    \begin{matrix}
      Q \times P & p_1 & p_2 & p_3    & p_4    & \ldots \\
      q_1        & 1   & 3   & 6      & 10     &        \\
      q_2        & 2   & 5   & 9      &        &        \\
      q_3        & 4   & 8   & \ddots &        &        \\
      q_4        & 7   &     &        & \ddots &        \\
      \vdots
    \end{matrix}
  \end{align*}

  meaning $P \times Q$ is countable. The bijection that corresponds to that table is
  \begin{align*}
    f(p_i, q_j) = \dfrac{(i + j - 1)(i + j)}{2} - (i - 1)
  \end{align*}
\end{proof}

\begin{claim}
  $\mathbb{R}$ is \textbf{\textit{not}} countable.
\end{claim}

\begin{proof}[Cantor's Diagonal Argument]
  We proceed by contradiction.\footnote{Cantor's diagonalization proof has been called one of the most beautiful proofs in mathematics.} Suppose that $\mathbb{R}$ is countable, so we can enumerate its elements as $\mathbb{R} = \set{r_1, r_2, \ldots}$. The decimal representation of each element in $\mathbb{R}$ is then
  \begin{align*}
    r_1 & = N_1.d_{11}d_{12}d_{13}\ldots \\
    r_2 & = N_2.d_{21}d_{22}d_{23}\ldots \\
    r_3 & = N_3.d_{31}d_{32}d_{33}\ldots \\
    \vdots
  \end{align*}

  where $N_i \in \mathbb{Z}$ and $x_{ij} \in \set{0, \ldots, 9}$. Take $y = N.y_1y_2y_3\ldots$ s.t. $y_i \ne x_{ii}$ and $y$ doesn't have an alternative representation (so $y$ doesn't end in all $0$s or all $9$s; but we can do this, since for any $x_{ii}$ we have $7$ numbers to choose from other than $0, 9$, or $x_{ii}$). $y \in \mathbb{R}$ but $y \ne r_j$ for all $j$, a contradiction.
\end{proof}

Why doesn't this proof work for $\mathbb{Q}$?\footnote{If we try to use that same proof to show $\mathbb{Q}$ is not countable there is actually no guarantee that the number $y$ we construct will be an element of $\mathbb{Q}$. We have already established there are numbers that are not in $\mathbb{Q}$, whereas $\mathbb{R}$ is actually defined to be complete (this is a formal term, but intuitively it means that $\mathbb{R}$ has \textit{all} the numbers).}

\begin{tacomment}{1}
  While we often work with $\mathbb{R}$, the real numbers aren't actually in reality. We made them up. There is no such thing as $\pi$ pies: Even at the sub-atomic level, there will be a finite number of atoms, and any numbers we derive will be integers or rationals.

  Furthermore, it is not obvious what it means to make choices from uncountable sets.  Of course we can make a choice from a set that is uncountable, you might think: It has infinitely many more elements than a countable set! It seems trivial, but if we are not careful we end up with some rather unintuitive paradoxes.

  For example, a consequence of the axiom of choice (which allows us to make a choice out of uncountable sets in an intuitive way) is the Banach-Tarski paradox: Take any ball in 3-dimensional space (or higher); we can partition the ball into finitely many pieces and rearrange (move and rotate) those pieces into two balls identical to the first one.

  So in general it will be useful to think of statements that are true for $\mathbb{R}$ as being the convenient version of something that we should be able to show in $\mathbb{Q}$. We will see later on that while $\mathbb{R}$ is infinitely larger than $\mathbb{Q}$, the rational numbers are \keyword{dense} in the reals. Informally, $\forall a, b \in \mathbb{R} ~~ \exists q \in Q$ s.t.
  \[
    a < q < b
  \]

  whenever $a < b$. (``Informally'' because the concept of density here depends on the order, $<$, and in general we will be able to define that being dense means without it.)
\end{tacomment}

% ---------------------------------------------------------------------
\subsection{Metric Spaces}
\label{sub:metric_spaces}

\begin{definition}[distance]\label{def:lecture1_distance}
  A function $d: X \times X \to \mathbb{R}_+$ with $X \ne \varnothing$ is called a \keyword{distance} or a \keyword{metric} on $X$ if
  \begin{enumerate}
    \item $d(x, y) = 0 \iff x = y$,

    \item $d(x, y) = d(y, x)$ (it is symmetric), and

    \item $d(x, y) \le d(x, z) + d(z, y)$ (the triangle inequality holds).
  \end{enumerate}
\end{definition}

Note that the triangle inequality says that you cannot ``shorten'' the distance between two points if you first ``stop by'' a third point. It might be equal (if $z$ is in the path from $x$ to $y$ in some sense), but it can never be smaller. Last, note that we defined $d$ to be $\ge 0$ for all $x, y$.

\begin{definition}[metric space]\label{def:lecture1_space}
  A \keyword{metric space} $(X, d)$ is a non-empty set $X$ with a metric $d$ defined on $X$.
\end{definition}

Some examples of metric spaces:
\begin{enumerate}
  \item For any $X \ne 0$, one way to metricize the space is the discrete metric
    \begin{align*}
      d(x, y) = \begin{cases}
        1 & x \ne y \\
        0 & x = y
      \end{cases}
    \end{align*}

  \item $\mathbb{R}^N$ with the euclidean distance,
    \begin{align*}
      d(x, y)
      = \norm{x - y}
      = \sqrt{\sum^{N}_{i = 1} (x_i - y_i)^2}
    \end{align*}

  \item More generally, consider the $L^P$ norm, $d_p$, for $1 \le p \le \infty$ on $\mathbb{R}^N$ for $N \in \mathbb{N}$
    \begin{align*}
      d_p(x, y)
      =
      \begin{cases}
        \left(\displaystyle\sum^{N}_{i = 1} |x_i - y_i|^p\right)^{1 / p}
          & 1 \le p < \infty \\[12pt]
        \displaystyle\max_{i = 1, \ldots, N} |x_i - y_i|
          & p = \infty
      \end{cases}
    \end{align*}

    $(\mathbb{R}^N, d_p)$ is a metric space. $d_2$ is the euclidean distance, but it turns out that, while geometrically intuitive, it's not necessary to preserve a lot of the properties we care about.
    \begin{figure}[H]
      \centering
      \caption{Unit ``circle'' in $\mathbb{R}^2$ under different $L^p$ norms}
      \label{fig:unit_circle_in_r_2_under_different_l_p_norms}
      \begin{tikzpicture}
        \begin{axis}[name=plot1
          %,title=
          ,width=8cm
          ,height=8cm
          ,ymin=-1.5
          ,ymax=1.5
          ,xmin=-1.6
          ,xmax=1.6
          ,domain=-1:1
          ,ylabel=$x_2$
          ,xlabel=$x_1$
        ]
        % around 0
        % y = (1 - x^p)^(1/p)
        \addplot [smooth, samples = 100, domain=0:1] {abs(1 - x)};
        \addplot [smooth, samples = 100, domain=-1:0] {abs(x + 1)};
        \addplot [smooth, samples = 100, opacity=0.6] {(1 - x^2)^(1/2)};
        \addplot [smooth, samples = 200, opacity=0.5] {(1 - x^4)^(1/4)};
        \addplot [smooth, samples = 400, opacity=0.4] {(1 - x^8)^(1/8)};
        \addplot [smooth, samples = 400, opacity=0.3] {(1 - x^12)^(1/12)};
        \addplot [smooth, samples = 400, opacity=0.2] {(1 - x^16)^(1/16)};

        \addplot [smooth, samples = 100, domain=0:1] {-abs(1 - x)};
        \addplot [smooth, samples = 100, domain=-1:0] {-abs(x + 1)};
        \addplot [smooth, samples = 100, opacity=0.6] {-(1 - x^2)^(1/2)};
        \addplot [smooth, samples = 200, opacity=0.5] {-(1 - x^4)^(1/4)};
        \addplot [smooth, samples = 400, opacity=0.4] {-(1 - x^8)^(1/8)};
        \addplot [smooth, samples = 400, opacity=0.3] {-(1 - x^12)^(1/12)};
        \addplot [smooth, samples = 400, opacity=0.2] {-(1 - x^16)^(1/16)};

        \draw [->, >=latex] (axis cs:-0.25,  0.35) to[bend right=15] (axis cs:0.48,  0.52);
        \draw [->, >=latex] (axis cs:-0.25,  0.10) to[bend right=15] (axis cs:0.7,   0.7);
        \draw [->, >=latex] (axis cs:-0.25, -0.15) to[bend right=15] (axis cs:0.825, 0.825);
        \draw [->, >=latex] (axis cs:-0.25, -0.40) to[bend right=15] (axis cs:0.9,   0.9);
        \draw [->, >=latex] (axis cs:1.25, 1.25) to[bend right=15] (axis cs:1, 1);

        \node[left] at (axis cs:-0.25,  0.35) {$d_1$};
        \node[left] at (axis cs:-0.25,  0.10) {$d_2$};
        \node[left] at (axis cs:-0.25, -0.15) {$d_4$};
        \node[left] at (axis cs:-0.25, -0.40) {$d_8$};

        \node[right] at (axis cs:1.25, 1.25) {$d_{\infty}$};
        \draw [-]
          (axis cs:-1, -1) --
          (axis cs:-1,  1) --
          (axis cs: 1,  1) --
          (axis cs: 1, -1) --
          (axis cs:-1, -1)
        ;
        \end{axis}
      \end{tikzpicture}
    \end{figure}

    In the figure above we can get some intuition for why we defined the $d_{\infty}$ norm as the max; graphically on $\mathbb{R}^2$, we can see this is the natural extension of $d_p$ as $p \to \infty$.
\end{enumerate}

While it can be useful to developan abstract understanding of metric spaces, for the purposes of this class it's fine if you think of metric spaces as Euclidean space (i.e. $(\mathbb{R}^N, d_2)$, which I will simply denote as $\mathbb{R}^N$).

% ---------------------------------------------------------------------
\subsection{Introduction to Topology}
\label{sub:introduction_to_topology}

\begin{definition}[$\varepsilon$-neighborhood]\label{def:lecture1_neighborhood}
  Let $X$ be a metric space. For each $x \in X$ we define the \keyword{$\varepsilon$-neighborhood} of $x$ as
  \begin{align*}
    N_{\varepsilon, X}(x) = \Fset{y \in X: d(x, y) < \varepsilon}
  \end{align*}
\end{definition}

On $\mathbb{R}$, we can see this is just the interval of length $2\varepsilon$ centered around $x$; on $\mathbb{R}^2$ this is a circle, on $\mathbb{R}^3$ it is a ball, and so on. Neighborhoods are never empty, since at least $x \in N_{\varepsilon, X}(x)$.
\begin{remark}
  In Euclidean space an $\varepsilon$-neighborhood is called an \keyword{$\varepsilon$-ball}. Henceforth we will use $\varepsilon$-balls in place of neighborhoods, denoting the $\varepsilon$-ball centered around a point $x$ as $B_{\varepsilon}(x)$. However, the results we discuss will hold using the more abstract idea of a neighborhood in any metric space.
\end{remark}

\begin{definition}[open]\label{def:lecture1_open_set}
  Let $S \subseteq \mathbb{R}^{N}$; $S$ is \keyword{open} in $\mathbb{R}^N$ if $\forall s \in S ~~ \exists \varepsilon > 0$ s.t. $B_{\varepsilon}(x) \subseteq S$.
\end{definition}

\begin{definition}[closed]\label{def:lecture1_closed_set}
  Let $S \subseteq \mathbb{R}^{N}$; $S$ is \keyword{closed} if its complement $S^C = \mathbb{R}^N \setminus S$ is open.
\end{definition}

Some examples of open and closed sets:\footnote{Note the definition of openness uses $\subseteq$ instead of $\subset$. This can be an important distinction, and gets to the fact openness and closeness are not intrinsic properties of subsets: They are tied to the set they are defined in as well as the metric that has been defined on the space. Similarly, a set is defined as closed if its complement \textit{in a given space} is open. All this might make you suspect that sets can be both open or closed if we simply change what they are open or closed relative to, and you would be right!}
\begin{enumerate}
  \item The interval $(0, 1)$ in $\mathbb{R}$ is open. Take any $0 < x < 1$ and let
    \begin{align*}
      \varepsilon \equiv \min\Fset{x - 0.5 (0 + x), 0.5 (1 - x))}
    \end{align*}

    Note $N_{\varepsilon, \mathbb{R}}(x) = (x - \varepsilon, x + \varepsilon)$, so $0 < 0.5x \le x - \varepsilon < x < x + \varepsilon \le 0.5(1 + x) < 1$, means $N_{\varepsilon, \mathbb{R}}(x) \subseteq (0, 1)$.

  \item The interval $[0, 1]$ is closed in $\mathbb{R}$. $(-\infty, 0)$ is open. For any $x < 0$, take $\varepsilon = |x| / 2$ and we have $-\infty < x - \varepsilon < x < x + \varepsilon < 0$. Similarly, for $x > 1$ take $\varepsilon = (x + 1) / 2$ and we get $1 < x - \varepsilon < x < x + \varepsilon < \infty$. Since its complement is open, $[0, 1]$ is closed.

  \item The interval $[0, 1)$ is open in $\mathbb{R}_+$. This is a bit less obvious. $[0, 1)$ is not open in $\mathbb{R}$ because if we take $x = 0$, any $\varepsilon > 0$ gives $x - \varepsilon < 0$, and thus the $\varepsilon$-neighborhood is not in $[0, 1)$. However, in $\mathbb{R}_+$ there are no points $< 0$, so there is nothing to contradict $[0, 1)$ being open.

    What about $[0, 1)$ in $\mathbb{R}$? Is it open or closed?\footnote{It's actually neither.}
\end{enumerate}

% \begin{claim}
%   Every metric space $X$ is open and closed with respect to itself.
% \end{claim}
%
% \begin{proof}
%   Openness holds since $N_{\varepsilon, X}(x) \subseteq X$ by definition (had we used $\subset$ in the definition of openness, this would not be true). To see that it's closed, note $X \setminus X = \varnothing$, and the empty set is open by vacuity.
%
%   We can also see the empty set is open by contrapositive: If for every $\varepsilon > 0$ we have $N_{\varepsilon, X}(x) \cancel\subseteq \varnothing$, then $x \notin \varnothing$. There is nothing in the empty set, so $N_{\varepsilon, X}(x) \cancel\subseteq \varnothing$ and $x \notin \varnothing$ is true for every $x \in X$. Hence $\varnothing$ is open.
% \end{proof}

\begin{claim}
  The empty set $\varnothing$ is both open and closed.
\end{claim}

\begin{proof}
  The complement of the empty set is $\mathbb{R}^N \setminus \varnothing = \mathbb{R}^N$, the space itself. Take any $x \in \mathbb{R}^N$ and any $\varepsilon$-ball $B_{\varepsilon}(x)$; by definition $B_{\varepsilon}(x) \subseteq \mathbb{R}^N$. Since $\mathbb{R}^N$ is open, $\varnothing$ is closed.

  The empty set is open by vacuity: Pick $\varepsilon > 0$ and any $x \in \varnothing$; we have $B_{\varepsilon}(x) = \varnothing \subseteq \varnothing$. Another way to see it is the contrapositive: $\forall \varepsilon > 0$, if $B_{\varepsilon}(x) \cancel\subseteq \varnothing$ then $B_{\varepsilon}(x) \subseteq \mathbb{R}^N$, which implies $x \in \mathbb{R}^N$ and $x \notin \mathbb{R}^N \setminus \mathbb{R}^N = \varnothing$. (Note this  also implies $\mathbb{R}^N$ is closed.)
\end{proof}

Can you prove that $\varepsilon$-balls are open?\footnote{Hint: You can use the triangle inequality.}
\begin{definition}[clopen]\label{def:lecture1_clopen}
  A set is ``\keyword{clopen}'' if it is both closed and open.
\end{definition}

% \begin{example}
%   Consider any space $X$ and the discrete metric
%   \[
%     d(x, y) = \begin{cases}
%       1 & x \ne y \\
%       0 & x = y
%     \end{cases}
%   \]
%
%   Every subset $S \subseteq X$ is clopen. Take $S \ne \varnothing$ and $\varepsilon = 0.5$ and we can see that $N_{\varepsilon, X}(s) = \set{s} \subseteq S$ for any $s \in S$. So $S$ is open. Take $X \setminus S$ and $r \notin S$. Again, $\varepsilon = 0.5$ gives $N_{\varepsilon, X}(r) = \set{r} \cancel\subseteq S$, so $N_{\varepsilon, X}(r) \subseteq X \setminus S$, meaning it's open, so $S$ is closed.
% \end{example}

\begin{claim}
\begin{itemize}[label=$\bullet$]
  \item Any union of open sets is open.

  \item A finite intersection of open sets is open.

  \item Any intersection of closed sets is closed.

  \item A finite union of closed sets is closed.
\end{itemize}
\end{claim}

To see why we require a finite intersection for open sets, consider $I_n = (-1/n, 1/n)$ in $\mathbb{R}$. Each set is open, but $\bigcap^{\infty}_{n = 1} I_n = \set{0}$, and singletons are closed in $\mathbb{R}$, so the infinite intersection is closed. Similarly, we can see why we need a finite union for closed sets: $\bigcup_{x \in (0, 1)} \set{x} = (0, 1)$; we just discussed how singletons are closed, but the infinite union can be open.
\begin{definition}[interior, closure, boundary]\label{def:lecture1_interior_closure_boundary}
  \begin{enumerate}
    \item The union of every open set $O$ s.t. $O \subseteq S$ is the \keyword{interior} of $S$. We denote it as $\interior(S)$.

    \item The intersection of every closed set $K$ s.t. $S \subseteq K$ is the \keyword{closure} of $S$. We denote it as $\closure(S)$.

    \item The \keyword{boundary} of $S$ is the set difference between the closure and the interior, $\boundary(S) = \closure(S) \setminus \interior(S)$.
  \end{enumerate}
\end{definition}

\begin{claim}
  An open set is its own interior. A closed set is its own closure.
\end{claim}

The interior is always open, since arbitrary unions of open sets are open; similarly, the closure is always closed, since arbitrary intersections of closed sets are closed.

\begin{definition}
  Let $S \subseteq \mathbb{R}^N$; $S$ is \keyword{bounded} if $\exists \varepsilon > 0, s \in S$ s.t. $S \subseteq B_{\varepsilon}(x)$.
\end{definition}

\begin{definition}
  Let $S \subseteq \mathbb{R}$; $a$ is an \keyword{upper bound} for $S$ if $\forall s \in S$ we have $s \le a$. The least upper bound is called the \keyword{supremum}, denoted $\sup S$.
\end{definition}

\begin{definition}
  Let $S \subseteq \mathbb{R}$; $b$ is an \keyword{lower bound} for $S$ if $\forall s \in S$ we have $s \ge b$. The greatest lower bound is called the \keyword{infimum}, denoted $\inf S$.
\end{definition}

\begin{claim}
  Let $S \subseteq \mathbb{R}$. $a = \sup S$ iff $~ \forall c < a ~~ \exists s \in S$ s.t. $c < s$; similarly, $b = \inf S$ iff $~ \forall c > b ~~ \exists s \in S$ s.t. $c > s$.
\end{claim}

\begin{proof}
  Let $a = \sup S$ and take any $c \in S$ s.t. $c < a$. By contradiction suppose $\forall s \in S$ we have $s \le c < a$, so $c$ is an upper bound smaller than $a$, which contradicts the definition of the $\sup$. Now let $a$ be s.t. for any $c \in S$ with $c < a$ there exists some $s \in S$ s.t. $c < s$. By contradiction, if $a \ne \sup S$ then by definition of the $\sup$ it must be that $\sup(S) < a$; however, by premise we now have $\exists s \in S$ s.t. $\sup S < s$, which contradicts the definition of the $\sup$. Hence $a = \sup S$.

  The arguments for the $\inf$ are entirely analogous.
\end{proof}

\begin{remark}
  For any $S \subseteq \mathbb{R}$ that is bounded above, $\sup S \in \mathbb{R}$; similarly, for any $S \subseteq \mathbb{R}$ that is bounded below, $\inf S \in \mathbb{R}$. This is not obvious as, for example, the set $\mathbb{Q} \cap (-\pi, \pi)$ does not have a $\sup$ or an $\inf$ in $\mathbb{Q}$. The fact this is true in $\mathbb{R}$ is a consequence of a property called ``completeness.'' We will not discuss it in depth in this class, but intuitively it means that $\mathbb{R}$ has no ``holes'' (unlike, say, $\mathbb{Q}$). The real line $\mathbb{R}$ is actually constructed to have this property, and you may encounter references to the \textit{completeness axiom}.
\end{remark}

\begin{definitionx}[Archimedean Property]\label{def:lecture1_archimedean}
  $\forall \varepsilon > 0 ~~ \exists N \in \mathbb{N}$ s.t. $0 < 1/N < \varepsilon$.
\end{definitionx}

\begin{claim}
  $\mathbb{Q}$ is \keyword{dense} in $\mathbb{R}$. In this context, $\forall a, b \in \mathbb{R}$ s.t. $a < b ~~ \exists q \in \mathbb{Q}$ s.t. $a < q < b$.
\end{claim}

\begin{proof}
  Density is defined as a more general property of metric spaces, but in the context of the real line the above is a good characterization: You can always find a rational number between any two real numbers.  Since $b - a > 0$, the \nameref{def:lecture1_archimedean} gives $\exists n \in \mathbb{N}$ s.t. $0 < 1/n < (b - a)$, or $1 < n(b - a)$. Take any integer $m \in \mathbb{Z}$ s.t. $na < m < nb$ (at least one such integer exists since the difference between $na$ and $nb$ is greater than $1$). Since $n \in \mathbb{N}$ is strictly positive, dividing  through preserves the inequalities, and
  \[
    a < m/n < b
  \]

  Let $q \equiv m/n \in \mathbb{Q}$ and we have completed the proof.
\end{proof}

% ---------------------------------------------------------------------
\subsection{Limits}
\label{sub:limits}

\begin{definition}
  $s \in \mathbb{R}^N$ is a \keyword{limit point} of a set $S$ if $\forall \varepsilon > 0$ there is some $x \in S$ s.t. $s \ne x$ and $d(s, x) < \varepsilon$.
\end{definition}

Intuitively, it's any point in $S$ that can be arbitrarily close to other points in $S$.
\begin{definition}
  Let $f: S \to \mathbb{R}$ and $s$ be a limit point of $S$. We say $L$ is the \keyword{limit} of $f(x)$ as $x$ approaches $s$,
  \[
    \lim_{x \to s} f(x) = L
  \]

  if $\forall \varepsilon > 0 ~~ \exists \delta > 0$ s.t.
  \[
    d(x, a) < \delta \implies |f(x) - L| < \varepsilon
  \]
\end{definition}

\begin{definition}
  Let $S \subseteq \mathbb{R}$, $f: S \to \mathbb{R}$, and $s$ a limit point of $S$. The limit from above or from the right is
  \[
    \lim_{x \to s^+} f(x) = L_+
  \]

  if $\forall \varepsilon > 0 ~~ \exists \delta > 0$ s.t.
  \[
    s < x < s + \delta
    \implies
    |f(x) - L_+| < \varepsilon
  \]

  Similarly for the limit from below (or from the left):
  \[
    \lim_{x \to s^-} f(x) = L_-
  \]

  We have that $\lim_{x \to s} f(x)$ exists if $L_{+} = L_{-} = L$.
\end{definition}

\clearpage
\printindex

% ---------------------------------------------------------------------
\end{document}
